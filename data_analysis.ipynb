{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os, json\n",
    "from json import JSONDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(from_year, to_year):\n",
    "    if not 2000 < int(from_year) < 2050 or not 2000 < int(from_year) < 2050:\n",
    "        return []\n",
    "    all_holidays = []\n",
    "    for i in range(from_year, to_year+1):\n",
    "        r = requests.get(f'https://date.nager.at/api/v2/publicholidays/{i}/CH')\n",
    "        all_holidays.extend(r.json())\n",
    "    return all_holidays\n",
    "\n",
    "def set_date_index(df, col='date'):\n",
    "    return df.set_index(pd.to_datetime(df[col])).drop(col, axis=1)\n",
    "\n",
    "def filter_canton(df, can='BS'):\n",
    "    return df[[(str('CH-' + can) in row) if row is not None else True for row in df.counties]]\n",
    "\n",
    "def get_holiday_data(canton='BS', from_year=2015, to_year=2019):\n",
    "    holiday_data = get_json(from_year, to_year)\n",
    "    holiday_df = (pd.DataFrame.from_records(holiday_data)\n",
    "                  .pipe(set_date_index)\n",
    "                  .pipe(filter_canton, can=canton))\n",
    "    return holiday_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 105: Basel\n",
    "def import_weather_data(station_index=105):    \n",
    "    stationdata = []\n",
    "    station_error = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(\"weather_data/2018\"):\n",
    "        for file in files: \n",
    "            if not file.endswith(\".json\"): continue\n",
    "            filename = os.path.join(root, file)\n",
    "            try:\n",
    "                with open(filename) as json_file:\n",
    "                    data = json.load(json_file)\n",
    "                    stationdata.append(data[station_index])\n",
    "            except UnicodeDecodeError:\n",
    "                station_error = station_error + 1\n",
    "            except JSONDecodeError:\n",
    "                station_error = station_error + 1\n",
    "    print (\"Loaded: %d - errors: %d\" % (len(stationdata), station_error))\n",
    "    pandata = pd.DataFrame(stationdata)\n",
    "    pandata = pandata.drop(columns=['code','station'])\n",
    "    return pandata\n",
    "\n",
    "def clean_weather_data(weather_df): \n",
    "    weather_df['temperature'] = pd.to_numeric(weather_df['temperature'])\n",
    "    weather_df['sunshine'] = pd.to_numeric(weather_df['sunshine'])\n",
    "    weather_df['precipitation'] = pd.to_numeric(weather_df['precipitation'])\n",
    "    return weather_df.set_index(pd.to_datetime(weather_df['dateTime'])).drop('dateTime', axis=1).sort_index()\n",
    "\n",
    "def get_weather_score():\n",
    "    weather_data = (import_weather_data()\n",
    "                    .pipe(clean_weather_data))\n",
    "    # first version, just take sunshine value\n",
    "    return weather_data[['sunshine']]\n",
    "\n",
    "def get_metheo_weather():\n",
    "    metheo = pd.read_csv('raw_data/metheo.csv', delimiter=';')\n",
    "    metheo['Date'] = pd.to_datetime(metheo[['Year','Month','Day','Hour','Minute']])\n",
    "    metheo = metheo.drop(['Year','Month','Day','Hour','Minute'], axis=1).set_index('Date')\n",
    "    metheo['SWR'] = metheo.pop('Shortwave Radiation')\n",
    "    return metheo\n",
    "\n",
    "def get_basel_kanton_weather():\n",
    "    basel_wetter = pd.read_csv('raw_data/100051.csv', delimiter=';', parse_dates=True)\n",
    "    basel_wetter.set_index(pd.to_datetime(basel_wetter['Datum/Zeit'])).drop('Datum/Zeit', axis=1).sort_index().dropna()\n",
    "    return basel_wetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_basel_data():\n",
    "    data = pd.read_csv(\"raw_data/Basel_Daten.csv\", delimiter=';')\n",
    "    stamps = [x.split('+')[0] for x in data['DateTimeFrom'].values]\n",
    "    data = data.assign(Time=pd.to_datetime(stamps.copy(), format=\"%Y-%m-%dT%H:%M:%S\"))\n",
    "    return data\n",
    "\n",
    "def clean_location_data(location_df):\n",
    "    location_df = location_df.set_index('Time')\n",
    "    location_df = location_df.assign(Day=location_df.index.day)\n",
    "    return location_df\n",
    "\n",
    "def get_location_data(df, location):\n",
    "    mask = df['SiteName'] == location\n",
    "    return df[mask], df[~mask]\n",
    "\n",
    "def get_group_data(df, group):\n",
    "    mask = df['Group'] == group\n",
    "    return df[mask], df[~mask]\n",
    "\n",
    "def get_location_split_dict(data):\n",
    "    location_dict = {}\n",
    "    #Alle Orte\n",
    "    locs = sorted(list(set(data['SiteName'])))\n",
    "    for loc in locs:\n",
    "        location_df, data = get_location_data(data, loc)\n",
    "        location_dict[loc] = clean_location_data(location_df)\n",
    "    return location_dict\n",
    "\n",
    "def get_group_split_dict(data):\n",
    "    group_dict = {}\n",
    "    location_group = {'350 Dreirosenbrücke': 3, '352 Johanniterbrücke': 3, '354 Wettsteinbrücke': 3,\n",
    "                      '403 Heuwaage-Viadukt': 3, '405 Dorenbachviadukt': 2, '659 Schlachthofstrasse': 3,\n",
    "                      '660 Flughafenstrasse': 3, '802 Klybeckstrasse 113/Kirche': 1, '803 Johanniterbrücke': 1,\n",
    "                      '804 Rosentalstrasse 29/28': 2, '805 Rebgasse 11/28': 1, '806 Gerbergasse': 1,\n",
    "                      '807 Güterstrasse 180/183': 1, '808 Wolfschlucht-Promenade': 1, '809 Allschwilerstrasse 77/86': 1,\n",
    "                      '810 Neubadstrasse 124/137': 1, '811 Mülhauserstrasse 110/122': 1, '812 Wettsteinbrücke': 1,\n",
    "                      '813 Hardstrasse 66/77': 1, '814 Elisabethenstrasse 46*': 1, '815 Mittlere Rheinbrücke': 1,\n",
    "                      '816 Schmiedgasse 4/7 (Riehen)': 1, '817 Elisabethenanlage': 1, '901 Peter-Merian Weg': 3,\n",
    "                      '902 Viaduktstrasse': 3, '903 Äussere Baselstrasse 328': 2, '904 Hammerstrasse 90': 2,\n",
    "                      '905 Leimenstrasse 4': 2, '906 Hegenheimerstrasse 44': 2, '907 Wasgenring 62': 2,\n",
    "                      '908 Grenzacherstrasse (Kraftwerk)': 2, '909 General Guisan-Strasse 104': 2,\n",
    "                      '910 St. Galler-Ring 101': 2, '911 Birskopfsteg': 2, '912 Elsässerstrasse 261/260': 2,\n",
    "                      '913 Burgfelderstrasse': 3, '914 Hiltalingerstrasse': 1, '915 Luzernerring-Brücke': 3,\n",
    "                      '916 Stückisteg': 1, '917 Schwarzwaldbrücke': 3, '918 Elsässerrheinweg': 0,\n",
    "                      '919 St. Alban-Rheinweg': 2, '920 J. Burckhardt-Strasse': 3}\n",
    "    data['Group'] = data['SiteName'].apply(lambda x: location_group[x])\n",
    "    for group in range(4):\n",
    "        group_df, data = get_group_data(data, group)\n",
    "        group_dict[group] = clean_location_data(group_df)\n",
    "    return group_dict\n",
    "\n",
    "#TODO CREATE REAL SAMPLES\n",
    "def resample_location_data(location_df, frequency):\n",
    "    if frequency == 'D':\n",
    "        cols = ['Total']\n",
    "    elif frequency == 'H':\n",
    "        cols = ['Total', 'Month', 'Day', 'Holiday', 'Weekday', 'HourFrom', 'Temperature', 'Precipitation', 'SWR']\n",
    "    else:\n",
    "        print(\"INCORRECT FREQUENCY\")\n",
    "    location_df = location_df[cols].resample(frequency).sum()\n",
    "    return location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df = get_holiday_data()\n",
    "#weather_data = (import_weather_data()\n",
    "#                .pipe(clean_weather_data))[['sunshine', 'precipitation', 'temperature']]\n",
    "metheo = get_metheo_weather()\n",
    "data = import_basel_data()\n",
    "data['Holiday'] = [1 if x in holiday_df.index.values else 0 for x in data['Time']]\n",
    "data = pd.merge(data, metheo, left_on='Time', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_hourly_sum = {}\n",
    "location_daily_sum = {}\n",
    "for loc, loc_data in get_group_split_dict(data).items():\n",
    "    location_daily_sum[loc] = resample_location_data(loc_data, 'D')\n",
    "    location_hourly_sum[loc] = resample_location_data(loc_data, 'H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>HourFrom</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>SWR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-26 19:00:00</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>18.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-26 20:00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-26 21:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>11.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-26 22:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>12.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-11-26 23:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>12.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42984 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Total  Month  Day  Holiday  Weekday  HourFrom  \\\n",
       "Time                                                                 \n",
       "2015-01-01 00:00:00     23      1    1        0        3         0   \n",
       "2015-01-01 01:00:00     20      1    1        0        3         1   \n",
       "2015-01-01 02:00:00      5      1    1        0        3         2   \n",
       "2015-01-01 03:00:00      5      1    1        0        3         3   \n",
       "2015-01-01 04:00:00      2      1    1        0        3         4   \n",
       "...                    ...    ...  ...      ...      ...       ...   \n",
       "2019-11-26 19:00:00     41     22   52        0        2        38   \n",
       "2019-11-26 20:00:00     14     22   52        0        2        40   \n",
       "2019-11-26 21:00:00     12     22   52        0        2        42   \n",
       "2019-11-26 22:00:00      4     22   52        0        2        44   \n",
       "2019-11-26 23:00:00      4     22   52        0        2        46   \n",
       "\n",
       "                     Temperature  Precipitation  SWR  \n",
       "Time                                                  \n",
       "2015-01-01 00:00:00        -0.86            0.0  0.0  \n",
       "2015-01-01 01:00:00        -0.84            0.0  0.0  \n",
       "2015-01-01 02:00:00        -0.77            0.0  0.0  \n",
       "2015-01-01 03:00:00        -1.36            0.0  0.0  \n",
       "2015-01-01 04:00:00        -1.68            0.0  0.0  \n",
       "...                          ...            ...  ...  \n",
       "2019-11-26 19:00:00        18.60            0.0  0.0  \n",
       "2019-11-26 20:00:00        13.76            0.0  0.0  \n",
       "2019-11-26 21:00:00        11.94            0.0  0.0  \n",
       "2019-11-26 22:00:00        12.34            0.0  0.0  \n",
       "2019-11-26 23:00:00        12.44            0.0  0.0  \n",
       "\n",
       "[42984 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_hourly_sum[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds] *",
   "language": "python",
   "name": "conda-env-ds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
